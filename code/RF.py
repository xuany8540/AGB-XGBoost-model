import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import time  # âœ… ç”¨äºè®¡æ—¶
import os

# è®¾ç½®matplotlibçš„å­—ä½“ä¸ºæ”¯æŒä¸­æ–‡çš„å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']  # æŒ‡å®šé»˜è®¤å­—ä½“ä¸ºé»‘ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# è¯»å–Excelæ–‡ä»¶
file_path = r".results\Feature selection\Lasso(VIF).xlsx"
df = pd.read_excel(file_path)

# æŒ‡å®šç›®æ ‡åˆ—ï¼ˆç”Ÿç‰©é‡ï¼‰å¹¶åˆ†ç¦»å‡ºç‰¹å¾åˆ—
target_column = 'ç”Ÿç‰©é‡'
X = df.drop(target_column, axis=1)
y = df[target_column]

# æ•°æ®é›†æŒ‰ç…§8:2è¿›è¡Œåˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# åˆ›å»ºéšæœºæ£®æ—æ¨¡å‹
model = RandomForestRegressor(n_estimators=500, random_state=80)

# è¿›è¡Œ10æŠ˜äº¤å‰éªŒè¯
cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='r2')

# âœ… è®¡æ—¶å¼€å§‹
start_time = time.time()

# è®­ç»ƒæ¨¡å‹
model.fit(X_train, y_train)

# é¢„æµ‹æµ‹è¯•é›†
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# âœ… è®¡æ—¶ç»“æŸ
end_time = time.time()
print(f"\nâ± æ¨¡å‹è®­ç»ƒ + é¢„æµ‹è€—æ—¶ï¼š{end_time - start_time:.4f} ç§’")

# æ¨¡å‹è¯„ä¼°
train_r2 = r2_score(y_train, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
train_mse = mean_squared_error(y_train, y_train_pred)
train_aic = len(y_train) * np.log(train_mse) + 2 * (X_train.shape[1] + 1)
train_bic = len(y_train) * np.log(train_mse) + np.log(len(y_train)) * (X_train.shape[1] + 1)

test_r2 = r2_score(y_test, y_test_pred)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
test_mse = mean_squared_error(y_test, y_test_pred)
test_aic = len(y_test) * np.log(test_mse) + 2 * (X_test.shape[1] + 1)
test_bic = len(y_test) * np.log(test_mse) + np.log(len(y_test)) * (X_test.shape[1] + 1)

# æ‰“å°è¯„ä¼°ç»“æœ
print("è®­ç»ƒé›†è¯„ä¼°ç»“æœ:")
print(f"R^2: {train_r2:.4f}")
print(f"MSE: {train_mse:.4f}")
print(f"RMSE: {train_rmse:.4f}")
print(f"AIC: {train_aic:.4f}")
print(f"BIC: {train_bic:.4f}")

print("\næµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
print(f"R^2: {test_r2:.4f}")
print(f"MSE: {test_mse:.4f}")
print(f"RMSE: {test_rmse:.4f}")
print(f"AIC: {test_aic:.4f}")
print(f"BIC: {test_bic:.4f}")
# æ•£ç‚¹å›¾ï¼šçœŸå®å€¼ vs é¢„æµ‹å€¼ï¼Œå¹¶æ·»åŠ y=xè¾…åŠ©çº¿
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_train, y=y_train_pred, label='è®­ç»ƒé›†', alpha=0.5)
sns.scatterplot(x=y_test, y=y_test_pred, label='æµ‹è¯•é›†', alpha=0.5)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2, label='1:1çº¿')  # æ·»åŠ y=xè¾…åŠ©çº¿ï¼Œçº¢è‰²
plt.annotate(f'$R^2$: {test_r2:.2f}\nMSE: {test_mse:.2f}\nRMSE: {test_rmse:.2f}',
             xy=(0.85, 0.75), xycoords='axes fraction',  # åæ ‡ä½ç½®(0,0)æ˜¯å·¦ä¸‹è§’ï¼Œ(1,1)æ˜¯å³ä¸Šè§’
             bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.5, edgecolor='black'))
plt.legend()
plt.xlabel('çœŸå®å€¼')
plt.ylabel('é¢„æµ‹å€¼')
# ä¿å­˜æ•£ç‚¹å›¾
output_dir = r".results\RF"
scatter_output_path = os.path.join(output_dir, "RF_ScatterPlot_True_vs_Predicted.png")
plt.savefig(scatter_output_path, dpi=300, bbox_inches='tight')
print(f"âœ… æ•£ç‚¹å›¾å·²ä¿å­˜è‡³ï¼š{scatter_output_path}")
plt.show()

# å°æç´å›¾ï¼šçœŸå®å€¼ vs é¢„æµ‹å€¼
data = pd.DataFrame({'å€¼': np.concatenate([y_test, y_test_pred]), 'å°æç´å›¾': np.repeat(['çœŸå®å€¼', 'é¢„æµ‹å€¼'], len(y_test))})
plt.figure(figsize=(8, 6))
sns.violinplot(x='å°æç´å›¾', y='å€¼', data=data)
# ä¿å­˜å°æç´å›¾
output_dir = r"G:\Github\AGB-XGBoost-model\results"
violin_output_path = os.path.join(output_dir, "RF_ViolinPlot_True_vs_Predicted.png")
plt.savefig(violin_output_path, dpi=300, bbox_inches='tight')
print(f"âœ… å°æç´å›¾å·²ä¿å­˜è‡³ï¼š{violin_output_path}")
plt.show()

output_dir = r"G:\Github\AGB-XGBoost-model\results"
os.makedirs(output_dir, exist_ok=True)
output_file = os.path.join(output_dir, "RF_Model_Evaluation.txt")  # âœ… æ–‡ä»¶åä¸ºéšæœºæ£®æ—æ¨¡å‹ç»“æœ

evaluation_text = f"""

â± æ¨¡å‹è®­ç»ƒ + é¢„æµ‹è€—æ—¶ï¼š{end_time - start_time:.4f} ç§’

ğŸ“Œ è®­ç»ƒé›†è¯„ä¼°æŒ‡æ ‡ï¼š
- R^2       : {train_r2:.4f}
- MSE       : {train_mse:.4f}
- RMSE      : {train_rmse:.4f}
- AIC       : {train_aic:.4f}
- BIC       : {train_bic:.4f}

ğŸ“Œ æµ‹è¯•é›†è¯„ä¼°æŒ‡æ ‡ï¼š
- R^2       : {test_r2:.4f}
- MSE       : {test_mse:.4f}
- RMSE      : {test_rmse:.4f}
- AIC       : {test_aic:.4f}
- BIC       : {test_bic:.4f}

ğŸ“ æ–‡ä»¶ä¿å­˜è·¯å¾„ï¼š{output_file}
ğŸ“… é¡¹ç›®è¯´æ˜ï¼šæœ¬æ¨¡å‹åŸºäº VIF.xlsx ç‰¹å¾æ„å»ºï¼Œé‡‡ç”¨ Random Forest ç®—æ³•ï¼Œn_estimators=500ï¼Œä½¿ç”¨ 10 æŠ˜äº¤å‰éªŒè¯ï¼Œè®­ç»ƒé›†ä¸æµ‹è¯•é›†æ¯”ä¾‹ä¸º 9:1ã€‚

===========================================================
"""

with open(output_file, 'w', encoding='utf-8') as f:
    f.write(evaluation_text)

print(f"\nâœ… æ¨¡å‹è¯„ä¼°ç»“æœå·²ä¿å­˜ä¸º TXT æ–‡ä»¶ï¼š\n{output_file}")
